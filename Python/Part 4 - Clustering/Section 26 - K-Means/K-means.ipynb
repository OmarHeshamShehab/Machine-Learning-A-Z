{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0MRC0e0KhQ0S"},"source":["# K-means"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"LWd1UlMnhT2s"},"source":["## Importing the libraries"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"K1VMqkGvhc3-"},"source":["## Importing the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset = pd.read_csv(\"Mall_Customers.csv\")\n","X = dataset.iloc[:, [3, 4]].values"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YvxIPVyMhmKp"},"source":["## Using the elbow method to find the optimal number of clusters"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.cluster import KMeans\n","\n","wcss = []\n","\n","for i in range(1, 11):\n","    kmeans = KMeans(n_clusters=i, init=\"k-means++\", random_state=123)\n","    kmeans.fit(X)\n","    wcss.append(kmeans.inertia_)\n","plt.plot(range(1,11), wcss)\n","plt.title(\"The Elbow Method\")\n","plt.xlabel(\"Number of Clusters\")\n","plt.ylabel(\"WCSS\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kW3c7UYih0hT"},"source":["## Training the K-means model on the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["kmeans = KMeans(n_clusters=5, init=\"k-means++\", random_state=123)\n","y_kmeans=kmeans.fit_predict(X)\n","print(y_kmeans) # add one as the index starts from 0"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bb6jCOCQiAmP"},"source":["## Visualizing the clusters"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s=100, c=\"red\", label=\"Cluster 1\")\n","plt.scatter(\n","    X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s=100, c=\"blue\", label=\"Cluster 2\"\n",")\n","plt.scatter(\n","    X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s=100, c=\"green\", label=\"Cluster 3\"\n",")\n","plt.scatter(\n","    X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s=100, c=\"cyan\", label=\"Cluster 4\"\n",")\n","plt.scatter(\n","    X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s=100, c=\"magenta\", label=\"Cluster 5\"\n",")\n","plt.scatter(\n","    kmeans.cluster_centers_[:, 0],\n","    kmeans.cluster_centers_[:, 0],\n","    s=300,\n","    c=\"yellow\",\n","    label=\"Centroids\",\n",")\n","plt.title(\"Clusters of Customers\")\n","plt.xlabel(\"Annual Income (K$)\")\n","plt.ylabel(\"Spending Score (1~100)\")\n","plt.legend()\n","plt.show()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOsvB/iqEjYj3VN6C/JbvkE","collapsed_sections":[],"machine_shape":"hm","name":"logistic_regression.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":0}
